{
  "config": {
    "split": "train",
    "k": 5,
    "limit": 150,
    "model": "sentence-transformers/all-MiniLM-L6-v2",
    "modes": [
      "embeddings",
      "bm25",
      "tfidf",
      "lsi",
      "dpr"
    ],
    "granularities": [
      "paragraph",
      "sentence"
    ],
    "include_answerability": true
  },
  "paragraph_metrics": {
    "embeddings": {
      "paragraph": {
        "metrics": {
          "precision@k": 0.01732283464566929,
          "recall@k": 0.05643044619422572,
          "f1@k": 0.024704298326345575,
          "evaluated_questions": 127
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "precision@k": 0.02519685039370079,
          "recall@k": 0.08661417322834646,
          "f1@k": 0.03581654565906534,
          "evaluated_questions": 127
        },
        "n_questions": 150
      }
    },
    "bm25": {
      "paragraph": {
        "metrics": {
          "precision@k": 0.028346456692913385,
          "recall@k": 0.0910761154855643,
          "f1@k": 0.04022735794389338,
          "evaluated_questions": 127
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "precision@k": 0.022047244094488192,
          "recall@k": 0.06062992125984252,
          "f1@k": 0.029142379929781508,
          "evaluated_questions": 127
        },
        "n_questions": 150
      }
    },
    "tfidf": {
      "paragraph": {
        "metrics": {
          "precision@k": 0.015748031496062992,
          "recall@k": 0.04225721784776903,
          "f1@k": 0.02004976650645942,
          "evaluated_questions": 127
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "precision@k": 0.02677165354330709,
          "recall@k": 0.07769028871391076,
          "f1@k": 0.03582336298871732,
          "evaluated_questions": 127
        },
        "n_questions": 150
      }
    },
    "lsi": {
      "paragraph": {
        "metrics": {
          "precision@k": 0.0,
          "recall@k": 0.0,
          "f1@k": 0.0,
          "evaluated_questions": 127
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "precision@k": 0.0,
          "recall@k": 0.0,
          "f1@k": 0.0,
          "evaluated_questions": 127
        },
        "n_questions": 150
      }
    },
    "dpr": {
      "paragraph": {
        "metrics": {
          "precision@k": 0.01732283464566929,
          "recall@k": 0.05643044619422572,
          "f1@k": 0.024704298326345575,
          "evaluated_questions": 127
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "precision@k": 0.01732283464566929,
          "recall@k": 0.05643044619422572,
          "f1@k": 0.024704298326345575,
          "evaluated_questions": 127
        },
        "n_questions": 150
      }
    }
  },
  "granularity_compare": {
    "embeddings": {
      "mode": "embeddings",
      "n": 150,
      "paragraph_hit": 0.25333333333333335,
      "sentence_hit": 0.3466666666666667
    },
    "bm25": {
      "mode": "bm25",
      "n": 150,
      "paragraph_hit": 0.38666666666666666,
      "sentence_hit": 0.38666666666666666
    },
    "tfidf": {
      "mode": "tfidf",
      "n": 150,
      "paragraph_hit": 0.3466666666666667,
      "sentence_hit": 0.36666666666666664
    },
    "lsi": {
      "mode": "lsi",
      "n": 150,
      "paragraph_hit": 0.12666666666666668,
      "sentence_hit": 0.1
    },
    "dpr": {
      "mode": "dpr",
      "n": 150,
      "paragraph_hit": 0.25333333333333335,
      "sentence_hit": 0.25333333333333335
    }
  },
  "lex_vs_sem": {
    "lexical_win": 31,
    "semantic_win": 4,
    "both_win": 42,
    "both_lose": 73,
    "total": 150
  },
  "answerability": {
    "metrics": {
      "overall": {
        "total_questions": 150,
        "accuracy": 0.32,
        "macro_f1": 0.31006493506493504,
        "weighted_f1": 0.3740909090909091,
        "average_confidence": 0.2995945901858795
      },
      "answerable": {
        "count": 133,
        "precision": 0.9428571428571428,
        "recall": 0.24812030075187969,
        "f1": 0.39285714285714285,
        "support": 133
      },
      "unanswerable": {
        "count": 17,
        "precision": 0.13043478260869565,
        "recall": 0.8823529411764706,
        "f1": 0.22727272727272727,
        "support": 17
      },
      "confusion_matrix": {
        "true_negative": 33,
        "false_positive": 100,
        "false_negative": 2,
        "true_positive": 15
      }
    },
    "n_questions": 150
  },
  "started_at": 1759167087.9295743,
  "finished_at": 1759170211.714017,
  "duration_sec": 3123.7844426631927
}