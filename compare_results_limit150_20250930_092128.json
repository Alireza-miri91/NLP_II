{
  "config": {
    "split": "train",
    "k": 5,
    "limit": 150,
    "model": "sentence-transformers/all-MiniLM-L6-v2",
    "modes": [
      "embeddings",
      "bm25",
      "tfidf",
      "lsi",
      "dpr"
    ],
    "granularities": [
      "paragraph",
      "sentence"
    ],
    "include_answerability": true
  },
  "paragraph_metrics": {
    "embeddings": {
      "paragraph": {
        "metrics": {
          "precision@k": 0.01732283464566929,
          "recall@k": 0.05643044619422572,
          "f1@k": 0.024704298326345575,
          "evaluated_questions": 127
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "precision@k": 0.02519685039370079,
          "recall@k": 0.08661417322834646,
          "f1@k": 0.03581654565906534,
          "evaluated_questions": 127
        },
        "n_questions": 150
      }
    },
    "bm25": {
      "paragraph": {
        "metrics": {
          "precision@k": 0.028346456692913385,
          "recall@k": 0.0910761154855643,
          "f1@k": 0.04022735794389338,
          "evaluated_questions": 127
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "precision@k": 0.022047244094488192,
          "recall@k": 0.06062992125984252,
          "f1@k": 0.029142379929781508,
          "evaluated_questions": 127
        },
        "n_questions": 150
      }
    },
    "tfidf": {
      "paragraph": {
        "metrics": {
          "precision@k": 0.015748031496062992,
          "recall@k": 0.04225721784776903,
          "f1@k": 0.02004976650645942,
          "evaluated_questions": 127
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "precision@k": 0.02677165354330709,
          "recall@k": 0.07769028871391076,
          "f1@k": 0.03582336298871732,
          "evaluated_questions": 127
        },
        "n_questions": 150
      }
    },
    "lsi": {
      "paragraph": {
        "metrics": {
          "precision@k": 0.0,
          "recall@k": 0.0,
          "f1@k": 0.0,
          "evaluated_questions": 127
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "precision@k": 0.0,
          "recall@k": 0.0,
          "f1@k": 0.0,
          "evaluated_questions": 127
        },
        "n_questions": 150
      }
    },
    "dpr": {
      "paragraph": {
        "metrics": {
          "precision@k": 0.01732283464566929,
          "recall@k": 0.05643044619422572,
          "f1@k": 0.024704298326345575,
          "evaluated_questions": 127
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "precision@k": 0.01732283464566929,
          "recall@k": 0.05643044619422572,
          "f1@k": 0.024704298326345575,
          "evaluated_questions": 127
        },
        "n_questions": 150
      }
    }
  },
  "granularity_compare": {
    "embeddings": {
      "mode": "embeddings",
      "n": 150,
      "paragraph_hit": 0.25333333333333335,
      "sentence_hit": 0.3466666666666667
    },
    "bm25": {
      "mode": "bm25",
      "n": 150,
      "paragraph_hit": 0.38666666666666666,
      "sentence_hit": 0.38666666666666666
    },
    "tfidf": {
      "mode": "tfidf",
      "n": 150,
      "paragraph_hit": 0.3466666666666667,
      "sentence_hit": 0.36666666666666664
    },
    "lsi": {
      "mode": "lsi",
      "n": 150,
      "paragraph_hit": 0.12666666666666668,
      "sentence_hit": 0.1
    },
    "dpr": {
      "mode": "dpr",
      "n": 150,
      "paragraph_hit": 0.25333333333333335,
      "sentence_hit": 0.25333333333333335
    }
  },
  "lex_vs_sem": {
    "lexical_win": 31,
    "semantic_win": 4,
    "both_win": 42,
    "both_lose": 73,
    "total": 150
  },
  "answerability": {
    "embeddings": {
      "paragraph": {
        "metrics": {
          "overall": {
            "total_questions": 150,
            "accuracy": 0.32,
            "macro_f1": 0.31006493506493504,
            "weighted_f1": 0.3740909090909091,
            "average_confidence": 0.2995945901858795
          },
          "answerable": {
            "count": 133,
            "precision": 0.9428571428571428,
            "recall": 0.24812030075187969,
            "f1": 0.39285714285714285,
            "support": 133
          },
          "unanswerable": {
            "count": 17,
            "precision": 0.13043478260869565,
            "recall": 0.8823529411764706,
            "f1": 0.22727272727272727,
            "support": 17
          },
          "confusion_matrix": {
            "true_negative": 33,
            "false_positive": 100,
            "false_negative": 2,
            "true_positive": 15
          }
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "overall": {
            "total_questions": 150,
            "accuracy": 0.22666666666666666,
            "macro_f1": 0.22611634940402064,
            "weighted_f1": 0.2420755500207555,
            "average_confidence": 0.30758302651525204
          },
          "answerable": {
            "count": 133,
            "precision": 0.9047619047619048,
            "recall": 0.14285714285714285,
            "f1": 0.24675324675324675,
            "support": 133
          },
          "unanswerable": {
            "count": 17,
            "precision": 0.11627906976744186,
            "recall": 0.8823529411764706,
            "f1": 0.2054794520547945,
            "support": 17
          },
          "confusion_matrix": {
            "true_negative": 19,
            "false_positive": 114,
            "false_negative": 2,
            "true_positive": 15
          }
        },
        "n_questions": 150
      }
    },
    "bm25": {
      "paragraph": {
        "metrics": {
          "overall": {
            "total_questions": 150,
            "accuracy": 0.37333333333333335,
            "macro_f1": 0.33035714285714285,
            "weighted_f1": 0.4615476190476191,
            "average_confidence": 0.35685766801351604
          },
          "answerable": {
            "count": 133,
            "precision": 0.8545454545454545,
            "recall": 0.3533834586466165,
            "f1": 0.5,
            "support": 133
          },
          "unanswerable": {
            "count": 17,
            "precision": 0.09473684210526316,
            "recall": 0.5294117647058824,
            "f1": 0.16071428571428573,
            "support": 17
          },
          "confusion_matrix": {
            "true_negative": 47,
            "false_positive": 86,
            "false_negative": 8,
            "true_positive": 9
          }
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "overall": {
            "total_questions": 150,
            "accuracy": 0.34,
            "macro_f1": 0.31789995866060355,
            "weighted_f1": 0.41284828441504756,
            "average_confidence": 0.3312023317951631
          },
          "answerable": {
            "count": 133,
            "precision": 0.8863636363636364,
            "recall": 0.2932330827067669,
            "f1": 0.4406779661016949,
            "support": 133
          },
          "unanswerable": {
            "count": 17,
            "precision": 0.11320754716981132,
            "recall": 0.7058823529411765,
            "f1": 0.1951219512195122,
            "support": 17
          },
          "confusion_matrix": {
            "true_negative": 39,
            "false_positive": 94,
            "false_negative": 5,
            "true_positive": 12
          }
        },
        "n_questions": 150
      }
    },
    "tfidf": {
      "paragraph": {
        "metrics": {
          "overall": {
            "total_questions": 150,
            "accuracy": 0.11333333333333333,
            "macro_f1": 0.10179640718562874,
            "weighted_f1": 0.023073852295409182,
            "average_confidence": 0.0
          },
          "answerable": {
            "count": 133,
            "precision": 0.0,
            "recall": 0.0,
            "f1": 0.0,
            "support": 133
          },
          "unanswerable": {
            "count": 17,
            "precision": 0.11333333333333333,
            "recall": 1.0,
            "f1": 0.20359281437125748,
            "support": 17
          },
          "confusion_matrix": {
            "true_negative": 0,
            "false_positive": 133,
            "false_negative": 0,
            "true_positive": 17
          }
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "overall": {
            "total_questions": 150,
            "accuracy": 0.11333333333333333,
            "macro_f1": 0.10179640718562874,
            "weighted_f1": 0.023073852295409182,
            "average_confidence": 0.0
          },
          "answerable": {
            "count": 133,
            "precision": 0.0,
            "recall": 0.0,
            "f1": 0.0,
            "support": 133
          },
          "unanswerable": {
            "count": 17,
            "precision": 0.11333333333333333,
            "recall": 1.0,
            "f1": 0.20359281437125748,
            "support": 17
          },
          "confusion_matrix": {
            "true_negative": 0,
            "false_positive": 133,
            "false_negative": 0,
            "true_positive": 17
          }
        },
        "n_questions": 150
      }
    },
    "lsi": {
      "paragraph": {
        "metrics": {
          "overall": {
            "total_questions": 150,
            "accuracy": 0.11333333333333333,
            "macro_f1": 0.10179640718562874,
            "weighted_f1": 0.023073852295409182,
            "average_confidence": 0.0
          },
          "answerable": {
            "count": 133,
            "precision": 0.0,
            "recall": 0.0,
            "f1": 0.0,
            "support": 133
          },
          "unanswerable": {
            "count": 17,
            "precision": 0.11333333333333333,
            "recall": 1.0,
            "f1": 0.20359281437125748,
            "support": 17
          },
          "confusion_matrix": {
            "true_negative": 0,
            "false_positive": 133,
            "false_negative": 0,
            "true_positive": 17
          }
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "overall": {
            "total_questions": 150,
            "accuracy": 0.11333333333333333,
            "macro_f1": 0.10179640718562874,
            "weighted_f1": 0.023073852295409182,
            "average_confidence": 0.0
          },
          "answerable": {
            "count": 133,
            "precision": 0.0,
            "recall": 0.0,
            "f1": 0.0,
            "support": 133
          },
          "unanswerable": {
            "count": 17,
            "precision": 0.11333333333333333,
            "recall": 1.0,
            "f1": 0.20359281437125748,
            "support": 17
          },
          "confusion_matrix": {
            "true_negative": 0,
            "false_positive": 133,
            "false_negative": 0,
            "true_positive": 17
          }
        },
        "n_questions": 150
      }
    },
    "dpr": {
      "paragraph": {
        "metrics": {
          "overall": {
            "total_questions": 150,
            "accuracy": 0.32,
            "macro_f1": 0.31006493506493504,
            "weighted_f1": 0.3740909090909091,
            "average_confidence": 0.2995945901858795
          },
          "answerable": {
            "count": 133,
            "precision": 0.9428571428571428,
            "recall": 0.24812030075187969,
            "f1": 0.39285714285714285,
            "support": 133
          },
          "unanswerable": {
            "count": 17,
            "precision": 0.13043478260869565,
            "recall": 0.8823529411764706,
            "f1": 0.22727272727272727,
            "support": 17
          },
          "confusion_matrix": {
            "true_negative": 33,
            "false_positive": 100,
            "false_negative": 2,
            "true_positive": 15
          }
        },
        "n_questions": 150
      },
      "sentence": {
        "metrics": {
          "overall": {
            "total_questions": 150,
            "accuracy": 0.32,
            "macro_f1": 0.31006493506493504,
            "weighted_f1": 0.3740909090909091,
            "average_confidence": 0.2995945901858795
          },
          "answerable": {
            "count": 133,
            "precision": 0.9428571428571428,
            "recall": 0.24812030075187969,
            "f1": 0.39285714285714285,
            "support": 133
          },
          "unanswerable": {
            "count": 17,
            "precision": 0.13043478260869565,
            "recall": 0.8823529411764706,
            "f1": 0.22727272727272727,
            "support": 17
          },
          "confusion_matrix": {
            "true_negative": 33,
            "false_positive": 100,
            "false_negative": 2,
            "true_positive": 15
          }
        },
        "n_questions": 150
      }
    }
  },
  "started_at": 1759216891.8057346,
  "finished_at": 1759223138.9327743,
  "duration_sec": 6247.127039670944
}